{"cells":[{"cell_type":"markdown","metadata":{"id":"e6btaXukoEBt"},"source":["# Hand Gesture Recognition with YOLOv5\n","\n","This notebook demonstrates hand gesture recognition using the YOLOv5 object detection model. The model is trained to detect and classify various hand gestures such as **Fist**, **Open Palm**,**Peace Sign** and **Thumbs Up**. The training and testing are performed on a custom dataset of hand gesture images.\n"]},{"cell_type":"markdown","metadata":{"id":"g7OTky92pN9g"},"source":["‚ñ∂ This line of code clones the YOLOv5 repository from GitHub into the current directory.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3205,"status":"ok","timestamp":1709083989131,"user":{"displayName":"shima azizi","userId":"03537820371144014436"},"user_tz":-210},"id":"e6JeREvGrEFN","outputId":"4d920819-569f-43ce-eb97-e2bad0985a5e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Cloning into 'yolov5'...\n","remote: Enumerating objects: 16491, done.\u001b[K\n","remote: Counting objects: 100% (83/83), done.\u001b[K\n","remote: Compressing objects: 100% (74/74), done.\u001b[K\n","remote: Total 16491 (delta 27), reused 36 (delta 9), pack-reused 16408\u001b[K\n","Receiving objects: 100% (16491/16491), 15.17 MiB | 15.74 MiB/s, done.\n","Resolving deltas: 100% (11290/11290), done.\n"]}],"source":["!git clone https://github.com/ultralytics/yolov5"]},{"cell_type":"markdown","metadata":{"id":"9BWCyFzCqmee"},"source":["‚ö° Navigate to the YOLOv5 directory to install required packages.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Xwui6mnTrOAb"},"outputs":[],"source":["!cd /content/yolov5"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7569,"status":"ok","timestamp":1709084002826,"user":{"displayName":"shima azizi","userId":"03537820371144014436"},"user_tz":-210},"id":"reC7E_mermgo","outputId":"6c225081-35e4-4495-b041-aba8fdded440"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting gitpython\u003e=3.1.30 (from -r /content/yolov5/requirements.txt (line 5))\n","  Downloading GitPython-3.1.42-py3-none-any.whl (195 kB)\n","\u001b[?25l     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/195.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m195.4/195.4 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: matplotlib\u003e=3.3 in /usr/local/lib/python3.10/dist-packages (from -r /content/yolov5/requirements.txt (line 6)) (3.7.1)\n","Requirement already satisfied: numpy\u003e=1.23.5 in /usr/local/lib/python3.10/dist-packages (from -r /content/yolov5/requirements.txt (line 7)) (1.25.2)\n","Requirement already satisfied: opencv-python\u003e=4.1.1 in /usr/local/lib/python3.10/dist-packages (from -r /content/yolov5/requirements.txt (line 8)) (4.8.0.76)\n","Requirement already satisfied: Pillow\u003e=9.4.0 in /usr/local/lib/python3.10/dist-packages (from -r /content/yolov5/requirements.txt (line 9)) (9.4.0)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from -r /content/yolov5/requirements.txt (line 10)) (5.9.5)\n","Requirement already satisfied: PyYAML\u003e=5.3.1 in /usr/local/lib/python3.10/dist-packages (from -r /content/yolov5/requirements.txt (line 11)) (6.0.1)\n","Requirement already satisfied: requests\u003e=2.23.0 in /usr/local/lib/python3.10/dist-packages (from -r /content/yolov5/requirements.txt (line 12)) (2.31.0)\n","Requirement already satisfied: scipy\u003e=1.4.1 in /usr/local/lib/python3.10/dist-packages (from -r /content/yolov5/requirements.txt (line 13)) (1.11.4)\n","Collecting thop\u003e=0.1.1 (from -r /content/yolov5/requirements.txt (line 14))\n","  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n","Requirement already satisfied: torch\u003e=1.8.0 in /usr/local/lib/python3.10/dist-packages (from -r /content/yolov5/requirements.txt (line 15)) (2.1.0+cu121)\n","Requirement already satisfied: torchvision\u003e=0.9.0 in /usr/local/lib/python3.10/dist-packages (from -r /content/yolov5/requirements.txt (line 16)) (0.16.0+cu121)\n","Requirement already satisfied: tqdm\u003e=4.64.0 in /usr/local/lib/python3.10/dist-packages (from -r /content/yolov5/requirements.txt (line 17)) (4.66.2)\n","Collecting ultralytics\u003e=8.0.232 (from -r /content/yolov5/requirements.txt (line 18))\n","  Downloading ultralytics-8.1.19-py3-none-any.whl (716 kB)\n","\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m716.2/716.2 kB\u001b[0m \u001b[31m43.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas\u003e=1.1.4 in /usr/local/lib/python3.10/dist-packages (from -r /content/yolov5/requirements.txt (line 27)) (1.5.3)\n","Requirement already satisfied: seaborn\u003e=0.11.0 in /usr/local/lib/python3.10/dist-packages (from -r /content/yolov5/requirements.txt (line 28)) (0.13.1)\n","Requirement already satisfied: setuptools\u003e=65.5.1 in /usr/local/lib/python3.10/dist-packages (from -r /content/yolov5/requirements.txt (line 42)) (67.7.2)\n","Collecting gitdb\u003c5,\u003e=4.0.1 (from gitpython\u003e=3.1.30-\u003e-r /content/yolov5/requirements.txt (line 5))\n","  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n","\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: contourpy\u003e=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib\u003e=3.3-\u003e-r /content/yolov5/requirements.txt (line 6)) (1.2.0)\n","Requirement already satisfied: cycler\u003e=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib\u003e=3.3-\u003e-r /content/yolov5/requirements.txt (line 6)) (0.12.1)\n","Requirement already satisfied: fonttools\u003e=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib\u003e=3.3-\u003e-r /content/yolov5/requirements.txt (line 6)) (4.49.0)\n","Requirement already satisfied: kiwisolver\u003e=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib\u003e=3.3-\u003e-r /content/yolov5/requirements.txt (line 6)) (1.4.5)\n","Requirement already satisfied: packaging\u003e=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib\u003e=3.3-\u003e-r /content/yolov5/requirements.txt (line 6)) (23.2)\n","Requirement already satisfied: pyparsing\u003e=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib\u003e=3.3-\u003e-r /content/yolov5/requirements.txt (line 6)) (3.1.1)\n","Requirement already satisfied: python-dateutil\u003e=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib\u003e=3.3-\u003e-r /content/yolov5/requirements.txt (line 6)) (2.8.2)\n","Requirement already satisfied: charset-normalizer\u003c4,\u003e=2 in /usr/local/lib/python3.10/dist-packages (from requests\u003e=2.23.0-\u003e-r /content/yolov5/requirements.txt (line 12)) (3.3.2)\n","Requirement already satisfied: idna\u003c4,\u003e=2.5 in /usr/local/lib/python3.10/dist-packages (from requests\u003e=2.23.0-\u003e-r /content/yolov5/requirements.txt (line 12)) (3.6)\n","Requirement already satisfied: urllib3\u003c3,\u003e=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests\u003e=2.23.0-\u003e-r /content/yolov5/requirements.txt (line 12)) (2.0.7)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests\u003e=2.23.0-\u003e-r /content/yolov5/requirements.txt (line 12)) (2024.2.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch\u003e=1.8.0-\u003e-r /content/yolov5/requirements.txt (line 15)) (3.13.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch\u003e=1.8.0-\u003e-r /content/yolov5/requirements.txt (line 15)) (4.9.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch\u003e=1.8.0-\u003e-r /content/yolov5/requirements.txt (line 15)) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch\u003e=1.8.0-\u003e-r /content/yolov5/requirements.txt (line 15)) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch\u003e=1.8.0-\u003e-r /content/yolov5/requirements.txt (line 15)) (3.1.3)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch\u003e=1.8.0-\u003e-r /content/yolov5/requirements.txt (line 15)) (2023.6.0)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch\u003e=1.8.0-\u003e-r /content/yolov5/requirements.txt (line 15)) (2.1.0)\n","Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics\u003e=8.0.232-\u003e-r /content/yolov5/requirements.txt (line 18)) (9.0.0)\n","Requirement already satisfied: pytz\u003e=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas\u003e=1.1.4-\u003e-r /content/yolov5/requirements.txt (line 27)) (2023.4)\n","Collecting smmap\u003c6,\u003e=3.0.1 (from gitdb\u003c5,\u003e=4.0.1-\u003egitpython\u003e=3.1.30-\u003e-r /content/yolov5/requirements.txt (line 5))\n","  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n","Requirement already satisfied: six\u003e=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil\u003e=2.7-\u003ematplotlib\u003e=3.3-\u003e-r /content/yolov5/requirements.txt (line 6)) (1.16.0)\n","Requirement already satisfied: MarkupSafe\u003e=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2-\u003etorch\u003e=1.8.0-\u003e-r /content/yolov5/requirements.txt (line 15)) (2.1.5)\n","Requirement already satisfied: mpmath\u003e=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy-\u003etorch\u003e=1.8.0-\u003e-r /content/yolov5/requirements.txt (line 15)) (1.3.0)\n","Installing collected packages: smmap, gitdb, thop, gitpython, ultralytics\n","Successfully installed gitdb-4.0.11 gitpython-3.1.42 smmap-5.0.1 thop-0.1.1.post2209072238 ultralytics-8.1.19\n"]}],"source":["!pip install -r /content/yolov5/requirements.txt"]},{"cell_type":"markdown","metadata":{"id":"vNr9D3hgrT7l"},"source":["‚ñ∂ Install the Roboflow package and download the YOLOv5 hand gesture dataset from the Roboflow platform using the provided API key.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":15936,"status":"ok","timestamp":1709084028761,"user":{"displayName":"shima azizi","userId":"03537820371144014436"},"user_tz":-210},"id":"UG4sb7QUswBZ","outputId":"b8049dc2-79b4-44b7-fe4d-c4543ce68e44"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting roboflow\n","  Downloading roboflow-1.1.21-py3-none-any.whl (70 kB)\n","\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m70.2/70.2 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting certifi==2023.7.22 (from roboflow)\n","  Downloading certifi-2023.7.22-py3-none-any.whl (158 kB)\n","\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m158.3/158.3 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting chardet==4.0.0 (from roboflow)\n","  Downloading chardet-4.0.0-py2.py3-none-any.whl (178 kB)\n","\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m178.7/178.7 kB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting cycler==0.10.0 (from roboflow)\n","  Downloading cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\n","Collecting idna==2.10 (from roboflow)\n","  Downloading idna-2.10-py2.py3-none-any.whl (58 kB)\n","\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: kiwisolver\u003e=1.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.4.5)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from roboflow) (3.7.1)\n","Requirement already satisfied: numpy\u003e=1.18.5 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.25.2)\n","Collecting opencv-python-headless==4.8.0.74 (from roboflow)\n","  Downloading opencv_python_headless-4.8.0.74-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.1 MB)\n","\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m49.1/49.1 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: Pillow\u003e=7.1.2 in /usr/local/lib/python3.10/dist-packages (from roboflow) (9.4.0)\n","Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.8.2)\n","Collecting python-dotenv (from roboflow)\n","  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.31.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.16.0)\n","Collecting supervision (from roboflow)\n","  Downloading supervision-0.18.0-py3-none-any.whl (86 kB)\n","\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m86.7/86.7 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: urllib3\u003e=1.26.6 in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.0.7)\n","Requirement already satisfied: tqdm\u003e=4.41.0 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.66.2)\n","Requirement already satisfied: PyYAML\u003e=5.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (6.0.1)\n","Collecting requests-toolbelt (from roboflow)\n","  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n","\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting python-magic (from roboflow)\n","  Downloading python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n","Requirement already satisfied: contourpy\u003e=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib-\u003eroboflow) (1.2.0)\n","Requirement already satisfied: fonttools\u003e=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib-\u003eroboflow) (4.49.0)\n","Requirement already satisfied: packaging\u003e=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib-\u003eroboflow) (23.2)\n","Requirement already satisfied: pyparsing\u003e=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib-\u003eroboflow) (3.1.1)\n","Requirement already satisfied: charset-normalizer\u003c4,\u003e=2 in /usr/local/lib/python3.10/dist-packages (from requests-\u003eroboflow) (3.3.2)\n","Requirement already satisfied: defusedxml\u003c0.8.0,\u003e=0.7.1 in /usr/local/lib/python3.10/dist-packages (from supervision-\u003eroboflow) (0.7.1)\n","Requirement already satisfied: scipy\u003c2.0.0,\u003e=1.10.0 in /usr/local/lib/python3.10/dist-packages (from supervision-\u003eroboflow) (1.11.4)\n","Installing collected packages: python-magic, python-dotenv, opencv-python-headless, idna, cycler, chardet, certifi, supervision, requests-toolbelt, roboflow\n","  Attempting uninstall: opencv-python-headless\n","    Found existing installation: opencv-python-headless 4.9.0.80\n","    Uninstalling opencv-python-headless-4.9.0.80:\n","      Successfully uninstalled opencv-python-headless-4.9.0.80\n","  Attempting uninstall: idna\n","    Found existing installation: idna 3.6\n","    Uninstalling idna-3.6:\n","      Successfully uninstalled idna-3.6\n","  Attempting uninstall: cycler\n","    Found existing installation: cycler 0.12.1\n","    Uninstalling cycler-0.12.1:\n","      Successfully uninstalled cycler-0.12.1\n","  Attempting uninstall: chardet\n","    Found existing installation: chardet 5.2.0\n","    Uninstalling chardet-5.2.0:\n","      Successfully uninstalled chardet-5.2.0\n","  Attempting uninstall: certifi\n","    Found existing installation: certifi 2024.2.2\n","    Uninstalling certifi-2024.2.2:\n","      Successfully uninstalled certifi-2024.2.2\n","Successfully installed certifi-2023.7.22 chardet-4.0.0 cycler-0.10.0 idna-2.10 opencv-python-headless-4.8.0.74 python-dotenv-1.0.1 python-magic-0.4.27 requests-toolbelt-1.0.0 roboflow-1.1.21 supervision-0.18.0\n"]},{"data":{"application/vnd.colab-display-data+json":{"id":"6182b5d6468641a1945921b8f2ccfe1b","pip_warning":{"packages":["certifi","cycler"]}}},"metadata":{},"output_type":"display_data"}],"source":["!pip install roboflow"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20157,"status":"ok","timestamp":1709084057331,"user":{"displayName":"shima azizi","userId":"03537820371144014436"},"user_tz":-210},"id":"N-1zkAc3sThu","outputId":"18c00f8a-ad60-4717-f186-4ad4fafb6f39"},"outputs":[{"name":"stdout","output_type":"stream","text":["Enter your Roboflow API key: ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n","loading Roboflow workspace...\n","loading Roboflow project...\n"]},{"name":"stderr","output_type":"stream","text":["Downloading Dataset Version Zip in YOLOv5-Hand-Gesture-3 to yolov5pytorch:: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17414/17414 [00:02\u003c00:00, 6496.49it/s] "]},{"name":"stdout","output_type":"stream","text":["\n"]},{"name":"stderr","output_type":"stream","text":["\n","Extracting Dataset Version Zip to YOLOv5-Hand-Gesture-3 in yolov5pytorch:: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 828/828 [00:00\u003c00:00, 4870.50it/s]\n"]}],"source":["import getpass\n","from roboflow import Roboflow\n","\n","# Prompt user to enter API key\n","api_key = getpass.getpass(\"Enter your Roboflow API key: \")\n","\n","# Check if API key is provided\n","if not api_key:\n","    print(\"Error: API key not provided. Please enter your Roboflow API key.\")\n","else:\n","    # Use the API key\n","    rf = Roboflow(api_key=api_key)\n","    project = rf.workspace(\"dataset-bfndu\").project(\"yolov5-hand-gesture\")\n","    dataset = project.version(3).download(\"yolov5\")"]},{"cell_type":"markdown","metadata":{"id":"jqq7JPC9tQlN"},"source":["‚è≥ This line trains the YOLOv5 model with specific parameters such as image size, batch size, epochs, dataset configuration, initial weights, and caching enabled."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":405161,"status":"ok","timestamp":1709084479623,"user":{"displayName":"shima azizi","userId":"03537820371144014436"},"user_tz":-210},"id":"t792JuInf1ht","outputId":"d9e4ab34-ecb3-46f0-e3fc-30a30691ef28"},"outputs":[{"name":"stdout","output_type":"stream","text":["2024-02-28 01:34:41.340941: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-02-28 01:34:41.341001: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-02-28 01:34:41.342429: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=, data=/content/yolov5/YOLOv5-Hand-Gesture-3/data.yaml, hyp=yolov5/data/hyps/hyp.scratch-low.yaml, epochs=50, batch_size=10, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, evolve_population=yolov5/data/hyps, resume_evolve=None, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=yolov5/runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest, ndjson_console=False, ndjson_file=False\n","\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ‚úÖ\n","YOLOv5 üöÄ v7.0-287-g574331f9 Python-3.10.12 torch-2.1.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n","\n","\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n","\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 üöÄ runs in Comet\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir yolov5/runs/train', view at http://localhost:6006/\n","Downloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n","100% 755k/755k [00:00\u003c00:00, 133MB/s]\n","Downloading https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5s.pt to yolov5s.pt...\n","100% 14.1M/14.1M [00:00\u003c00:00, 356MB/s]\n","\n","Overriding model.yaml nc=80 with nc=4\n","\n","                 from  n    params  module                                  arguments                     \n","  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n","  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n","  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n","  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n","  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n","  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n","  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n","  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n","  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n","  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n"," 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n"," 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n"," 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n"," 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n"," 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n"," 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n"," 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n"," 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n"," 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n"," 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n"," 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n"," 24      [17, 20, 23]  1     24273  models.yolo.Detect                      [4, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n","Model summary: 214 layers, 7030417 parameters, 7030417 gradients, 16.0 GFLOPs\n","\n","Transferred 343/349 items from yolov5s.pt\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n","\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.00046875), 60 bias\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/yolov5/YOLOv5-Hand-Gesture-3/train/labels... 368 images, 0 backgrounds, 0 corrupt: 100% 368/368 [00:00\u003c00:00, 1683.22it/s]\n","\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/yolov5/YOLOv5-Hand-Gesture-3/train/labels.cache\n","\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.4GB ram): 100% 368/368 [00:01\u003c00:00, 205.36it/s]\n","\u001b[34m\u001b[1mval: \u001b[0mScanning /content/yolov5/YOLOv5-Hand-Gesture-3/valid/labels... 20 images, 0 backgrounds, 0 corrupt: 100% 20/20 [00:00\u003c00:00, 517.39it/s]\n","\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/yolov5/YOLOv5-Hand-Gesture-3/valid/labels.cache\n","\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.0GB ram): 100% 20/20 [00:00\u003c00:00, 105.49it/s]\n","\n","\u001b[34m\u001b[1mAutoAnchor: \u001b[0m2.19 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset ‚úÖ\n","Plotting labels to yolov5/runs/train/exp/labels.jpg... \n","Image sizes 640 train, 640 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1myolov5/runs/train/exp\u001b[0m\n","Starting training for 50 epochs...\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       0/49      2.14G     0.0709    0.02885    0.03466         20        640: 100% 37/37 [00:11\u003c00:00,  3.26it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:01\u003c00:00,  1.46s/it]\n","                   all         20         20     0.0036      0.938     0.0832     0.0239\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       1/49      2.65G    0.04584    0.02429    0.03186         20        640: 100% 37/37 [00:06\u003c00:00,  5.29it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00\u003c00:00,  3.42it/s]\n","                   all         20         20      0.188      0.438       0.33      0.141\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       2/49      2.65G    0.04224    0.02058    0.03078         17        640: 100% 37/37 [00:06\u003c00:00,  5.69it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00\u003c00:00,  2.83it/s]\n","                   all         20         20     0.0793      0.762       0.14     0.0591\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       3/49      2.65G    0.03886    0.01943    0.02972         20        640: 100% 37/37 [00:06\u003c00:00,  6.07it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00\u003c00:00,  4.36it/s]\n","                   all         20         20      0.319      0.689      0.366      0.167\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       4/49      2.65G    0.03377    0.01721    0.02886         21        640: 100% 37/37 [00:07\u003c00:00,  5.13it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00\u003c00:00,  4.31it/s]\n","                   all         20         20      0.237      0.794      0.353      0.182\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       5/49      2.65G    0.03401    0.01755    0.02907         16        640: 100% 37/37 [00:06\u003c00:00,  6.00it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00\u003c00:00,  4.79it/s]\n","                   all         20         20      0.018      0.875       0.13     0.0305\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       6/49      2.65G    0.03002    0.01676    0.03003         22        640: 100% 37/37 [00:07\u003c00:00,  5.26it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00\u003c00:00,  4.79it/s]\n","                   all         20         20      0.256      0.705      0.513      0.257\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       7/49      2.65G    0.02836    0.01659    0.02723         19        640: 100% 37/37 [00:06\u003c00:00,  6.16it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00\u003c00:00,  4.53it/s]\n","                   all         20         20      0.437      0.648      0.645      0.308\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       8/49      2.65G    0.02681    0.01548    0.02626         18        640: 100% 37/37 [00:06\u003c00:00,  5.61it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00\u003c00:00,  4.54it/s]\n","                   all         20         20      0.472      0.721      0.669      0.403\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       9/49      2.65G    0.02983    0.01532    0.02676         17        640: 100% 37/37 [00:06\u003c00:00,  5.50it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00\u003c00:00,  2.90it/s]\n","                   all         20         20      0.645      0.769      0.763      0.513\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      10/49      2.65G    0.02712    0.01452    0.02343         14        640: 100% 37/37 [00:05\u003c00:00,  6.18it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00\u003c00:00,  4.25it/s]\n","                   all         20         20      0.584      0.715      0.725       0.42\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      11/49      2.65G    0.02684    0.01457    0.02547         20        640: 100% 37/37 [00:06\u003c00:00,  5.37it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00\u003c00:00,  4.51it/s]\n","                   all         20         20      0.469      0.801      0.748      0.384\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      12/49      2.65G    0.02768    0.01385     0.0249         20        640: 100% 37/37 [00:05\u003c00:00,  6.22it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00\u003c00:00,  4.47it/s]\n","                   all         20         20      0.674       0.69      0.827      0.563\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      13/49      2.65G    0.02629    0.01438    0.02287         18        640: 100% 37/37 [00:06\u003c00:00,  5.38it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00\u003c00:00,  4.72it/s]\n","                   all         20         20      0.639      0.812      0.835      0.604\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      14/49      2.65G    0.02671    0.01407    0.02366         19        640: 100% 37/37 [00:05\u003c00:00,  6.18it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00\u003c00:00,  4.31it/s]\n","                   all         20         20      0.815      0.806      0.861      0.536\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      15/49      2.65G    0.02393    0.01388    0.01887         15        640: 100% 37/37 [00:06\u003c00:00,  5.35it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00\u003c00:00,  4.47it/s]\n","                   all         20         20      0.756      0.781      0.833      0.538\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      16/49      2.65G    0.02823    0.01266    0.02111         18        640: 100% 37/37 [00:07\u003c00:00,  4.94it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00\u003c00:00,  3.37it/s]\n","                   all         20         20      0.713      0.679      0.826      0.562\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      17/49      2.65G    0.02179    0.01376    0.01897         23        640: 100% 37/37 [00:06\u003c00:00,  6.16it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00\u003c00:00,  4.69it/s]\n","                   all         20         20      0.801      0.864      0.854       0.58\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      18/49      2.65G    0.02547    0.01363    0.01949         23        640: 100% 37/37 [00:06\u003c00:00,  5.41it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00\u003c00:00,  4.63it/s]\n","                   all         20         20      0.723      0.757       0.82      0.513\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      19/49      2.65G    0.02266    0.01294    0.01763         25        640: 100% 37/37 [00:06\u003c00:00,  6.13it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00\u003c00:00,  4.57it/s]\n","                   all         20         20      0.818      0.909      0.911      0.565\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      20/49      2.65G     0.0231     0.0132    0.01875         15        640: 100% 37/37 [00:06\u003c00:00,  5.41it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00\u003c00:00,  4.42it/s]\n","                   all         20         20      0.785      0.896      0.884      0.591\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      21/49      2.65G    0.02173    0.01241    0.01528         18        640: 100% 37/37 [00:05\u003c00:00,  6.20it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00\u003c00:00,  4.52it/s]\n","                   all         20         20      0.817       0.88       0.87      0.496\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      22/49      2.65G    0.02285    0.01321    0.01674         16        640: 100% 37/37 [00:06\u003c00:00,  5.35it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00\u003c00:00,  4.42it/s]\n","                   all         20         20      0.972      0.857      0.943      0.633\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      23/49      2.65G    0.02449    0.01283     0.0172         15        640: 100% 37/37 [00:06\u003c00:00,  6.14it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00\u003c00:00,  2.74it/s]\n","                   all         20         20      0.901      0.869      0.926      0.636\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      24/49      2.65G    0.02135    0.01247    0.01571         20        640: 100% 37/37 [00:06\u003c00:00,  5.77it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00\u003c00:00,  4.42it/s]\n","                   all         20         20      0.949      0.875      0.948      0.571\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      25/49      2.65G    0.02348    0.01189     0.0148         15        640: 100% 37/37 [00:06\u003c00:00,  5.40it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00\u003c00:00,  3.34it/s]\n","                   all         20         20       0.92      0.875      0.953      0.578\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      26/49      2.65G    0.02617    0.01279    0.01642         18        640: 100% 37/37 [00:05\u003c00:00,  6.36it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00\u003c00:00,  4.47it/s]\n","                   all         20         20      0.917      0.898      0.974      0.615\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      27/49      2.65G    0.02089    0.01279    0.01256         18        640: 100% 37/37 [00:07\u003c00:00,  5.21it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00\u003c00:00,  4.50it/s]\n","                   all         20         20      0.971      0.872      0.942      0.659\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      28/49      2.65G    0.01981    0.01259    0.01234         24        640: 100% 37/37 [00:05\u003c00:00,  6.32it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00\u003c00:00,  4.31it/s]\n","                   all         20         20      0.894      0.917      0.937      0.571\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      29/49      2.65G    0.02104    0.01293    0.01303         24        640: 100% 37/37 [00:06\u003c00:00,  5.37it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00\u003c00:00,  4.54it/s]\n","                   all         20         20      0.947      0.895      0.964      0.658\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      30/49      2.65G    0.01929    0.01284    0.01243         20        640: 100% 37/37 [00:05\u003c00:00,  6.25it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00\u003c00:00,  4.22it/s]\n","                   all         20         20       0.93      0.927      0.995      0.648\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      31/49      2.65G    0.01983    0.01165    0.01151         26        640: 100% 37/37 [00:06\u003c00:00,  5.42it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00\u003c00:00,  4.77it/s]\n","                   all         20         20      0.897      0.903      0.974      0.679\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      32/49      2.65G    0.02294    0.01217    0.01449         17        640: 100% 37/37 [00:05\u003c00:00,  6.19it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00\u003c00:00,  3.58it/s]\n","                   all         20         20      0.946       0.91      0.964      0.654\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      33/49      2.65G    0.01751    0.01192    0.01085         19        640: 100% 37/37 [00:06\u003c00:00,  5.88it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00\u003c00:00,  4.43it/s]\n","                   all         20         20      0.958      0.883       0.96      0.712\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      34/49      2.65G    0.02064    0.01126    0.01158         19        640: 100% 37/37 [00:06\u003c00:00,  5.32it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00\u003c00:00,  3.87it/s]\n","                   all         20         20      0.979      0.898       0.96      0.702\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      35/49      2.65G    0.01744     0.0118    0.01094         23        640: 100% 37/37 [00:05\u003c00:00,  6.29it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00\u003c00:00,  4.29it/s]\n","                   all         20         20      0.974      0.902      0.982       0.75\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      36/49      2.65G    0.02037    0.01214    0.01369         23        640: 100% 37/37 [00:06\u003c00:00,  5.36it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00\u003c00:00,  4.58it/s]\n","                   all         20         20      0.922      0.977      0.995        0.7\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      37/49      2.65G    0.01811    0.01209    0.01127         15        640: 100% 37/37 [00:06\u003c00:00,  6.14it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00\u003c00:00,  4.55it/s]\n","                   all         20         20      0.934      0.978      0.995      0.701\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      38/49      2.65G    0.01845     0.0114    0.01054         16        640: 100% 37/37 [00:06\u003c00:00,  5.32it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00\u003c00:00,  4.41it/s]\n","                   all         20         20      0.902          1      0.995      0.708\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      39/49      2.65G     0.0175    0.01254    0.01109         25        640: 100% 37/37 [00:07\u003c00:00,  5.24it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00\u003c00:00,  2.80it/s]\n","                   all         20         20        0.9          1      0.995      0.713\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      40/49      2.65G    0.01675    0.01185     0.0107         18        640: 100% 37/37 [00:06\u003c00:00,  5.70it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00\u003c00:00,  4.48it/s]\n","                   all         20         20      0.932          1      0.995      0.724\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      41/49      2.65G    0.01778    0.01128   0.009619         12        640: 100% 37/37 [00:06\u003c00:00,  5.73it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00\u003c00:00,  2.73it/s]\n","                   all         20         20      0.954          1      0.995      0.762\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      42/49      2.65G    0.01765    0.01137    0.01019         17        640: 100% 37/37 [00:05\u003c00:00,  6.26it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00\u003c00:00,  4.58it/s]\n","                   all         20         20      0.958          1      0.995      0.763\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      43/49      2.65G    0.01798    0.01079    0.01033         19        640: 100% 37/37 [00:06\u003c00:00,  5.35it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00\u003c00:00,  4.74it/s]\n","                   all         20         20      0.965          1      0.995       0.76\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      44/49      2.65G    0.01558    0.01106   0.008912         24        640: 100% 37/37 [00:05\u003c00:00,  6.18it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00\u003c00:00,  4.23it/s]\n","                   all         20         20      0.967          1      0.995       0.76\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      45/49      2.65G    0.01804    0.01101    0.01037         15        640: 100% 37/37 [00:06\u003c00:00,  5.31it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00\u003c00:00,  4.51it/s]\n","                   all         20         20      0.933          1      0.995      0.773\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      46/49      2.65G     0.0187    0.01089    0.01075         23        640: 100% 37/37 [00:05\u003c00:00,  6.30it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00\u003c00:00,  3.97it/s]\n","                   all         20         20      0.937          1      0.995      0.767\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      47/49      2.65G    0.01626    0.01057   0.009636         21        640: 100% 37/37 [00:06\u003c00:00,  5.40it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00\u003c00:00,  4.24it/s]\n","                   all         20         20       0.95          1      0.995      0.768\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      48/49      2.65G     0.0166    0.01094   0.009514         24        640: 100% 37/37 [00:05\u003c00:00,  6.26it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00\u003c00:00,  3.54it/s]\n","                   all         20         20      0.947          1      0.995       0.77\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      49/49      2.65G    0.01689    0.01095    0.00961         20        640: 100% 37/37 [00:06\u003c00:00,  5.51it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00\u003c00:00,  4.33it/s]\n","                   all         20         20      0.946          1      0.995      0.772\n","\n","50 epochs completed in 0.102 hours.\n","Optimizer stripped from yolov5/runs/train/exp/weights/last.pt, 14.5MB\n","Optimizer stripped from yolov5/runs/train/exp/weights/best.pt, 14.5MB\n","\n","Validating yolov5/runs/train/exp/weights/best.pt...\n","Fusing layers... \n","Model summary: 157 layers, 7020913 parameters, 0 gradients, 15.8 GFLOPs\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00\u003c00:00,  4.39it/s]\n","                   all         20         20      0.933          1      0.995      0.762\n","                  Fist         20          8      0.926          1      0.995      0.799\n","              OpenPalm         20          5      0.911          1      0.995      0.815\n","             PeaceSign         20          3      0.907          1      0.995      0.703\n","              ThumbsUp         20          4       0.99          1      0.995      0.732\n","Results saved to \u001b[1myolov5/runs/train/exp\u001b[0m\n"]}],"source":["!python /content/yolov5/train.py --img 640 --batch 10 --epochs 50 --data /content/yolov5/YOLOv5-Hand-Gesture-3/data.yaml  --weights yolov5s.pt --cache\n"]},{"cell_type":"markdown","metadata":{"id":"jf2VpeDjthq9"},"source":["üè∏ This line runs YOLOv5 detection on **test images** with specified parameters: weights, image size, confidence threshold, and image source directory."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8190,"status":"ok","timestamp":1709084902796,"user":{"displayName":"shima azizi","userId":"03537820371144014436"},"user_tz":-210},"id":"oMtFcxmWsy5r","outputId":"c34b93c4-ca7a-43d0-8686-b647046b36ca"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/content/yolov5/runs/train/exp/weights/best.pt'], source=/content/yolov5/YOLOv5-Hand-Gesture-3/test/images, data=yolov5/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.1, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_csv=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov5/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n","YOLOv5 üöÄ v7.0-287-g574331f9 Python-3.10.12 torch-2.1.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n","\n","Fusing layers... \n","Model summary: 157 layers, 7020913 parameters, 0 gradients, 15.8 GFLOPs\n","image 1/20 /content/yolov5/YOLOv5-Hand-Gesture-3/test/images/Fist_18-jpg_jpg.rf.c66bb45fe74d4688664b93d179282cc0.jpg: 640x640 2 Fists, 11.5ms\n","image 2/20 /content/yolov5/YOLOv5-Hand-Gesture-3/test/images/Fist_19-jpg_jpg.rf.d2a2802a47aa088fc233f4daa3b7ba7c.jpg: 640x640 1 Fist, 11.6ms\n","image 3/20 /content/yolov5/YOLOv5-Hand-Gesture-3/test/images/Fist_22-jpg_jpg.rf.b2a2828a1819367016d66a3d8901ee91.jpg: 640x640 1 Fist, 11.5ms\n","image 4/20 /content/yolov5/YOLOv5-Hand-Gesture-3/test/images/Fist_3-jpg_jpg.rf.dd0cfcb22a7777d4eefdb91b300e86bf.jpg: 640x640 1 Fist, 11.5ms\n","image 5/20 /content/yolov5/YOLOv5-Hand-Gesture-3/test/images/Fist_33-jpg_jpg.rf.1fc9a0dcf5e05d4d73c6931746088551.jpg: 640x640 1 Fist, 11.5ms\n","image 6/20 /content/yolov5/YOLOv5-Hand-Gesture-3/test/images/OpenPalm_15-jpg_jpg.rf.518827fcc9d8e55c1c9ebfcc9c18aba7.jpg: 640x640 1 OpenPalm, 11.5ms\n","image 7/20 /content/yolov5/YOLOv5-Hand-Gesture-3/test/images/OpenPalm_21-jpg_jpg.rf.d6fdc1555f88c6e5e21f666c39111c3f.jpg: 640x640 1 OpenPalm, 11.5ms\n","image 8/20 /content/yolov5/YOLOv5-Hand-Gesture-3/test/images/OpenPalm_37-jpg_jpg.rf.98b3484ca7d9f0bafef4953b8d8a3ce7.jpg: 640x640 1 OpenPalm, 11.5ms\n","image 9/20 /content/yolov5/YOLOv5-Hand-Gesture-3/test/images/OpenPalm_43-jpg_jpg.rf.bb76b70ab5270431bb2257ee3d27ae17.jpg: 640x640 1 OpenPalm, 11.5ms\n","image 10/20 /content/yolov5/YOLOv5-Hand-Gesture-3/test/images/OpenPalm_5-jpg_jpg.rf.1e54fc35e5ee32515cb617f6d6717fcb.jpg: 640x640 1 OpenPalm, 11.5ms\n","image 11/20 /content/yolov5/YOLOv5-Hand-Gesture-3/test/images/OpenPalm_6-jpg_jpg.rf.92c793c43e60d9645af8f0be0975fcc0.jpg: 640x640 1 OpenPalm, 11.5ms\n","image 12/20 /content/yolov5/YOLOv5-Hand-Gesture-3/test/images/OpenPalm_7-jpg_jpg.rf.61cf9186734cee7f7efadfe8982d9d8d.jpg: 640x640 1 OpenPalm, 11.5ms\n","image 13/20 /content/yolov5/YOLOv5-Hand-Gesture-3/test/images/PeaceSign_13-jpg_jpg.rf.85dce7aab4477ae870c10e81c59225bd.jpg: 640x640 1 PeaceSign, 11.5ms\n","image 14/20 /content/yolov5/YOLOv5-Hand-Gesture-3/test/images/PeaceSign_27-jpg_jpg.rf.69acf80c9144109234995613dbf71d13.jpg: 640x640 1 OpenPalm, 1 PeaceSign, 11.1ms\n","image 15/20 /content/yolov5/YOLOv5-Hand-Gesture-3/test/images/PeaceSign_5-jpg_jpg.rf.abee4e55230b278b3ce09e0bb5757fd2.jpg: 640x640 1 PeaceSign, 11.1ms\n","image 16/20 /content/yolov5/YOLOv5-Hand-Gesture-3/test/images/ThumbsUp_23-jpg_jpg.rf.046c0e6692fe10a35f08f99bd7fbdf74.jpg: 640x640 1 ThumbsUp, 11.0ms\n","image 17/20 /content/yolov5/YOLOv5-Hand-Gesture-3/test/images/ThumbsUp_24-jpg_jpg.rf.87736849049ed7301455e32c2da65426.jpg: 640x640 1 ThumbsUp, 11.0ms\n","image 18/20 /content/yolov5/YOLOv5-Hand-Gesture-3/test/images/ThumbsUp_3-jpg_jpg.rf.9aca40cf9089109fff70b4d49f3336ab.jpg: 640x640 1 ThumbsUp, 11.0ms\n","image 19/20 /content/yolov5/YOLOv5-Hand-Gesture-3/test/images/ThumbsUp_37-jpg_jpg.rf.15e3c61ee6b930121caf4d1d4f45dcde.jpg: 640x640 1 ThumbsUp, 11.0ms\n","image 20/20 /content/yolov5/YOLOv5-Hand-Gesture-3/test/images/ThumbsUp_38-jpg_jpg.rf.965fc0c49333c352a33e92a6483aa284.jpg: 640x640 1 ThumbsUp, 11.0ms\n","Speed: 0.5ms pre-process, 11.3ms inference, 28.2ms NMS per image at shape (1, 3, 640, 640)\n","Results saved to \u001b[1myolov5/runs/detect/exp3\u001b[0m\n"]}],"source":["!python /content/yolov5/detect.py --weights /content/yolov5/runs/train/exp/weights/best.pt --img 640 --conf 0.1 --source /content/yolov5/YOLOv5-Hand-Gesture-3/test/images\n"]},{"cell_type":"markdown","metadata":{"id":"n0KUt3Y7wruL"},"source":["‚úÖ This code will create a grid of subplots, with each subplot showing **test images along with its bounding box predictions**, allowing you to visually inspect the model's performance."]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":862,"output_embedded_package_id":"18FCNsX_M2U3YrQ9xUUTq1UgivW6N3WpB"},"executionInfo":{"elapsed":19228,"status":"ok","timestamp":1709085525106,"user":{"displayName":"shima azizi","userId":"03537820371144014436"},"user_tz":-210},"id":"QH2p6R0NywOa","outputId":"09672142-ac13-4b37-972f-26c5a73dddb6"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import matplotlib.image as mpimg\n","import glob\n","\n","# Get list of image file paths\n","image_paths = glob.glob(\"/content/yolov5/runs/detect/exp3/*.jpg\")\n","\n","# Define number of rows and columns for subplots\n","rows = 4\n","cols = 5\n","\n","# Create subplots with specified number of rows and columns\n","fig, axes = plt.subplots(rows, cols, figsize=(15, 15))\n","\n","# Flatten axes array to loop through it easily\n","axes = axes.flatten()\n","\n","# Loop through image paths and display each image\n","for i, image_path in enumerate(image_paths):\n","    # Read image\n","    image = mpimg.imread(image_path)\n","\n","    # Display image on corresponding subplot\n","    axes[i].imshow(image)\n","    axes[i].axis('off')  # Hide axis\n","\n","# Adjust layout to prevent overlap\n","plt.tight_layout()\n","plt.savefig('predicted.png')\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wnmuHbmxxG22"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyMSuwzf/sUokq6q6c8JWzln","gpuType":"T4","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
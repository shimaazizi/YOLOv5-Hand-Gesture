{"cells":[{"cell_type":"markdown","source":["# Hand Gesture Recognition with YOLOv5\n","\n","This notebook demonstrates hand gesture recognition using the YOLOv5 object detection model. The model is trained to detect and classify various hand gestures such as **Fist**, **Open Palm**,**Peace Sign** and **Thumbs Up**. The training and testing are performed on a custom dataset of hand gesture images.\n"],"metadata":{"id":"e6btaXukoEBt"}},{"cell_type":"markdown","source":["â–¶ This line of code clones the YOLOv5 repository from GitHub into the current directory.\n"],"metadata":{"id":"g7OTky92pN9g"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":638,"status":"ok","timestamp":1708884408855,"user":{"displayName":"shima azizi","userId":"03537820371144014436"},"user_tz":-210},"id":"e6JeREvGrEFN","outputId":"ab2df2b2-07d2-470b-e5ac-591772b00179"},"outputs":[{"name":"stdout","output_type":"stream","text":["fatal: destination path 'yolov5' already exists and is not an empty directory.\n"]}],"source":["!git clone https://github.com/ultralytics/yolov5"]},{"cell_type":"markdown","source":["âš¡ Navigate to the YOLOv5 directory to install required packages.\n"],"metadata":{"id":"9BWCyFzCqmee"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Xwui6mnTrOAb"},"outputs":[],"source":["!cd /content/yolov5"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6652,"status":"ok","timestamp":1708884458155,"user":{"displayName":"shima azizi","userId":"03537820371144014436"},"user_tz":-210},"id":"reC7E_mermgo","outputId":"6db1f3a5-202e-4118-df40-5663f792bd68"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: gitpython>=3.1.30 in /usr/local/lib/python3.10/dist-packages (from -r /content/yolov5/requirements.txt (line 5)) (3.1.42)\n","Requirement already satisfied: matplotlib>=3.3 in /usr/local/lib/python3.10/dist-packages (from -r /content/yolov5/requirements.txt (line 6)) (3.7.1)\n","Requirement already satisfied: numpy>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from -r /content/yolov5/requirements.txt (line 7)) (1.25.2)\n","Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from -r /content/yolov5/requirements.txt (line 8)) (4.8.0.76)\n","Requirement already satisfied: Pillow>=9.4.0 in /usr/local/lib/python3.10/dist-packages (from -r /content/yolov5/requirements.txt (line 9)) (9.4.0)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from -r /content/yolov5/requirements.txt (line 10)) (5.9.5)\n","Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from -r /content/yolov5/requirements.txt (line 11)) (6.0.1)\n","Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from -r /content/yolov5/requirements.txt (line 12)) (2.31.0)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from -r /content/yolov5/requirements.txt (line 13)) (1.11.4)\n","Requirement already satisfied: thop>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from -r /content/yolov5/requirements.txt (line 14)) (0.1.1.post2209072238)\n","Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from -r /content/yolov5/requirements.txt (line 15)) (2.1.0+cu121)\n","Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from -r /content/yolov5/requirements.txt (line 16)) (0.16.0+cu121)\n","Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from -r /content/yolov5/requirements.txt (line 17)) (4.66.2)\n","Requirement already satisfied: ultralytics>=8.0.232 in /usr/local/lib/python3.10/dist-packages (from -r /content/yolov5/requirements.txt (line 18)) (8.1.18)\n","Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from -r /content/yolov5/requirements.txt (line 27)) (1.5.3)\n","Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from -r /content/yolov5/requirements.txt (line 28)) (0.13.1)\n","Requirement already satisfied: setuptools>=65.5.1 in /usr/local/lib/python3.10/dist-packages (from -r /content/yolov5/requirements.txt (line 42)) (67.7.2)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython>=3.1.30->-r /content/yolov5/requirements.txt (line 5)) (4.0.11)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r /content/yolov5/requirements.txt (line 6)) (1.2.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r /content/yolov5/requirements.txt (line 6)) (0.10.0)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r /content/yolov5/requirements.txt (line 6)) (4.49.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r /content/yolov5/requirements.txt (line 6)) (1.4.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r /content/yolov5/requirements.txt (line 6)) (23.2)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r /content/yolov5/requirements.txt (line 6)) (3.1.1)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r /content/yolov5/requirements.txt (line 6)) (2.8.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r /content/yolov5/requirements.txt (line 12)) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r /content/yolov5/requirements.txt (line 12)) (2.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r /content/yolov5/requirements.txt (line 12)) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r /content/yolov5/requirements.txt (line 12)) (2023.7.22)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r /content/yolov5/requirements.txt (line 15)) (3.13.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r /content/yolov5/requirements.txt (line 15)) (4.9.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r /content/yolov5/requirements.txt (line 15)) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r /content/yolov5/requirements.txt (line 15)) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r /content/yolov5/requirements.txt (line 15)) (3.1.3)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r /content/yolov5/requirements.txt (line 15)) (2023.6.0)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->-r /content/yolov5/requirements.txt (line 15)) (2.1.0)\n","Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics>=8.0.232->-r /content/yolov5/requirements.txt (line 18)) (9.0.0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->-r /content/yolov5/requirements.txt (line 27)) (2023.4)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from cycler>=0.10->matplotlib>=3.3->-r /content/yolov5/requirements.txt (line 6)) (1.16.0)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython>=3.1.30->-r /content/yolov5/requirements.txt (line 5)) (5.0.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->-r /content/yolov5/requirements.txt (line 15)) (2.1.5)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->-r /content/yolov5/requirements.txt (line 15)) (1.3.0)\n"]}],"source":["!pip install -r /content/yolov5/requirements.txt"]},{"cell_type":"markdown","source":["â–¶ Install the Roboflow package and download the YOLOv5 hand gesture dataset from the Roboflow platform using the provided API key.\n"],"metadata":{"id":"vNr9D3hgrT7l"}},{"cell_type":"code","source":["!pip install roboflow"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UG4sb7QUswBZ","executionInfo":{"status":"ok","timestamp":1708888635460,"user_tz":-210,"elapsed":5535,"user":{"displayName":"shima azizi","userId":"03537820371144014436"}},"outputId":"0dc590e4-3182-4606-a345-24aa39861b65"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: roboflow in /usr/local/lib/python3.10/dist-packages (1.1.19)\n","Requirement already satisfied: certifi==2023.7.22 in /usr/local/lib/python3.10/dist-packages (from roboflow) (2023.7.22)\n","Requirement already satisfied: chardet==4.0.0 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.0.0)\n","Requirement already satisfied: cycler==0.10.0 in /usr/local/lib/python3.10/dist-packages (from roboflow) (0.10.0)\n","Requirement already satisfied: idna==2.10 in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.10)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.4.5)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from roboflow) (3.7.1)\n","Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.25.2)\n","Requirement already satisfied: opencv-python-headless==4.8.0.74 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.8.0.74)\n","Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from roboflow) (9.4.0)\n","Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.8.2)\n","Requirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.0.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.31.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.16.0)\n","Requirement already satisfied: supervision in /usr/local/lib/python3.10/dist-packages (from roboflow) (0.18.0)\n","Requirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.0.7)\n","Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.66.2)\n","Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (6.0.1)\n","Requirement already satisfied: requests-toolbelt in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.0.0)\n","Requirement already satisfied: python-magic in /usr/local/lib/python3.10/dist-packages (from roboflow) (0.4.27)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (1.2.0)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (4.49.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (23.2)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (3.1.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->roboflow) (3.3.2)\n","Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from supervision->roboflow) (0.7.1)\n","Requirement already satisfied: scipy<2.0.0,>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from supervision->roboflow) (1.11.4)\n"]}]},{"cell_type":"code","source":["import getpass\n","\n","# Prompt user to enter API key\n","api_key = getpass.getpass(\"Enter your Roboflow API key: \")\n","\n","# Check if API key is provided\n","if not api_key:\n","    print(\"Error: API key not provided. Please enter your Roboflow API key.\")\n","else:\n","    # Use the API key\n","    rf = Roboflow(api_key=api_key)\n","    project = rf.workspace(\"dataset-bfndu\").project(\"yolov5-hand-gesture\")\n","    dataset = project.version(3).download(\"yolov5\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N-1zkAc3sThu","executionInfo":{"status":"ok","timestamp":1708888663185,"user_tz":-210,"elapsed":24059,"user":{"displayName":"shima azizi","userId":"03537820371144014436"}},"outputId":"71edb4a4-c671-4846-d1dc-5e166d3bba38"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Enter your Roboflow API key: Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n","loading Roboflow workspace...\n","loading Roboflow project...\n"]}]},{"cell_type":"markdown","source":["â³ This line trains the YOLOv5 model with specific parameters such as image size, batch size, epochs, dataset configuration, initial weights, and caching enabled."],"metadata":{"id":"jqq7JPC9tQlN"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":416771,"status":"ok","timestamp":1708889193478,"user":{"displayName":"shima azizi","userId":"03537820371144014436"},"user_tz":-210},"id":"t792JuInf1ht","outputId":"d62b715c-b86f-45d9-de23-4e81d92a3f0d"},"outputs":[{"output_type":"stream","name":"stdout","text":["2024-02-25 19:19:40.237092: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-02-25 19:19:40.237148: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-02-25 19:19:40.238524: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=, data=/content/yolov5/YOLOv5-Hand-Gesture-3/data.yaml, hyp=yolov5/data/hyps/hyp.scratch-low.yaml, epochs=50, batch_size=10, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, evolve_population=yolov5/data/hyps, resume_evolve=None, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=yolov5/runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest, ndjson_console=False, ndjson_file=False\n","remote: Enumerating objects: 53, done.\u001b[K\n","remote: Counting objects: 100% (53/53), done.\u001b[K\n","remote: Compressing objects: 100% (25/25), done.\u001b[K\n","remote: Total 53 (delta 30), reused 51 (delta 28), pack-reused 0\u001b[K\n","Unpacking objects: 100% (53/53), 79.21 KiB | 1.93 MiB/s, done.\n","From https://github.com/ultralytics/yolov5\n"," * [new branch]        docstrings2 -> origin/docstrings2\n","\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 âœ…\n","YOLOv5 ðŸš€ v7.0-286-g41603da1 Python-3.10.12 torch-2.1.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n","\n","\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n","\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 ðŸš€ runs in Comet\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir yolov5/runs/train', view at http://localhost:6006/\n","Overriding model.yaml nc=80 with nc=4\n","\n","                 from  n    params  module                                  arguments                     \n","  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n","  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n","  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n","  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n","  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n","  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n","  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n","  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n","  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n","  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n"," 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n"," 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n"," 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n"," 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n"," 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n"," 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n"," 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n"," 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n"," 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n"," 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n"," 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n"," 24      [17, 20, 23]  1     24273  models.yolo.Detect                      [4, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n","Model summary: 214 layers, 7030417 parameters, 7030417 gradients, 16.0 GFLOPs\n","\n","Transferred 343/349 items from yolov5s.pt\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.00046875), 60 bias\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/yolov5/YOLOv5-Hand-Gesture-3/train/labels.cache... 368 images, 0 backgrounds, 0 corrupt: 100% 368/368 [00:00<?, ?it/s]\n","\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.4GB ram): 100% 368/368 [00:01<00:00, 198.31it/s]\n","\u001b[34m\u001b[1mval: \u001b[0mScanning /content/yolov5/YOLOv5-Hand-Gesture-3/valid/labels.cache... 20 images, 0 backgrounds, 0 corrupt: 100% 20/20 [00:00<?, ?it/s]\n","\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.0GB ram): 100% 20/20 [00:00<00:00, 56.24it/s]\n","\n","\u001b[34m\u001b[1mAutoAnchor: \u001b[0m2.19 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset âœ…\n","Plotting labels to yolov5/runs/train/exp7/labels.jpg... \n","Image sizes 640 train, 640 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1myolov5/runs/train/exp7\u001b[0m\n","Starting training for 50 epochs...\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       0/49      2.14G     0.0709    0.02885    0.03466         20        640: 100% 37/37 [00:11<00:00,  3.30it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  2.55it/s]\n","                   all         20         20     0.0036      0.938     0.0832     0.0239\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       1/49      2.65G    0.04584    0.02429    0.03186         20        640: 100% 37/37 [00:07<00:00,  4.92it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  3.89it/s]\n","                   all         20         20      0.188      0.438       0.33      0.141\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       2/49      2.65G    0.04224    0.02058    0.03078         17        640: 100% 37/37 [00:06<00:00,  6.16it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  4.72it/s]\n","                   all         20         20     0.0793      0.762       0.14     0.0591\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       3/49      2.65G    0.03886    0.01943    0.02972         20        640: 100% 37/37 [00:08<00:00,  4.29it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  4.11it/s]\n","                   all         20         20      0.319      0.689      0.366      0.167\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       4/49      2.65G    0.03377    0.01721    0.02886         21        640: 100% 37/37 [00:06<00:00,  6.16it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  4.39it/s]\n","                   all         20         20      0.237      0.794      0.353      0.182\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       5/49      2.65G    0.03401    0.01755    0.02907         16        640: 100% 37/37 [00:07<00:00,  4.88it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  4.88it/s]\n","                   all         20         20      0.018      0.875       0.13     0.0305\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       6/49      2.65G    0.03002    0.01676    0.03003         22        640: 100% 37/37 [00:06<00:00,  5.90it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  4.50it/s]\n","                   all         20         20      0.256      0.705      0.513      0.257\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       7/49      2.65G    0.02836    0.01659    0.02723         19        640: 100% 37/37 [00:07<00:00,  5.01it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  3.66it/s]\n","                   all         20         20      0.437      0.648      0.645      0.308\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       8/49      2.65G    0.02681    0.01548    0.02626         18        640: 100% 37/37 [00:06<00:00,  5.85it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  3.37it/s]\n","                   all         20         20      0.472      0.721      0.669      0.403\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","       9/49      2.65G    0.02983    0.01532    0.02676         17        640: 100% 37/37 [00:06<00:00,  5.62it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  4.56it/s]\n","                   all         20         20      0.645      0.769      0.763      0.513\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      10/49      2.65G    0.02712    0.01452    0.02343         14        640: 100% 37/37 [00:06<00:00,  5.38it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  3.43it/s]\n","                   all         20         20      0.584      0.715      0.725       0.42\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      11/49      2.65G    0.02684    0.01457    0.02547         20        640: 100% 37/37 [00:06<00:00,  5.75it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  4.47it/s]\n","                   all         20         20      0.469      0.801      0.748      0.384\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      12/49      2.65G    0.02768    0.01385     0.0249         20        640: 100% 37/37 [00:07<00:00,  5.07it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  2.98it/s]\n","                   all         20         20      0.674       0.69      0.827      0.563\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      13/49      2.65G    0.02629    0.01438    0.02287         18        640: 100% 37/37 [00:06<00:00,  6.15it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  4.47it/s]\n","                   all         20         20      0.639      0.812      0.835      0.604\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      14/49      2.65G    0.02671    0.01407    0.02366         19        640: 100% 37/37 [00:07<00:00,  4.89it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  4.34it/s]\n","                   all         20         20      0.815      0.806      0.861      0.536\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      15/49      2.65G    0.02393    0.01388    0.01887         15        640: 100% 37/37 [00:05<00:00,  6.23it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  4.50it/s]\n","                   all         20         20      0.756      0.781      0.833      0.538\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      16/49      2.65G    0.02823    0.01266    0.02111         18        640: 100% 37/37 [00:07<00:00,  4.85it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  4.44it/s]\n","                   all         20         20      0.713      0.679      0.826      0.562\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      17/49      2.65G    0.02179    0.01376    0.01897         23        640: 100% 37/37 [00:06<00:00,  6.16it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  4.61it/s]\n","                   all         20         20      0.801      0.864      0.854       0.58\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      18/49      2.65G    0.02547    0.01363    0.01949         23        640: 100% 37/37 [00:07<00:00,  4.88it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  4.42it/s]\n","                   all         20         20      0.723      0.757       0.82      0.513\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      19/49      2.65G    0.02266    0.01294    0.01763         25        640: 100% 37/37 [00:06<00:00,  6.07it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  4.52it/s]\n","                   all         20         20      0.818      0.909      0.911      0.565\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      20/49      2.65G     0.0231     0.0132    0.01875         15        640: 100% 37/37 [00:07<00:00,  4.66it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  4.39it/s]\n","                   all         20         20      0.785      0.896      0.884      0.591\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      21/49      2.65G    0.02173    0.01241    0.01528         18        640: 100% 37/37 [00:07<00:00,  5.21it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  2.64it/s]\n","                   all         20         20      0.817       0.88       0.87      0.496\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      22/49      2.65G    0.02285    0.01321    0.01674         16        640: 100% 37/37 [00:09<00:00,  4.02it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  4.34it/s]\n","                   all         20         20      0.972      0.857      0.943      0.633\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      23/49      2.65G    0.02449    0.01283     0.0172         15        640: 100% 37/37 [00:07<00:00,  4.94it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  2.36it/s]\n","                   all         20         20      0.901      0.869      0.926      0.636\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      24/49      2.65G    0.02135    0.01247    0.01571         20        640: 100% 37/37 [00:05<00:00,  6.23it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  3.77it/s]\n","                   all         20         20      0.949      0.875      0.948      0.571\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      25/49      2.65G    0.02348    0.01189     0.0148         15        640: 100% 37/37 [00:07<00:00,  4.85it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  4.51it/s]\n","                   all         20         20       0.92      0.875      0.953      0.578\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      26/49      2.65G    0.02617    0.01279    0.01642         18        640: 100% 37/37 [00:06<00:00,  5.61it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  4.23it/s]\n","                   all         20         20      0.917      0.898      0.974      0.615\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      27/49      2.65G    0.02089    0.01279    0.01256         18        640: 100% 37/37 [00:07<00:00,  4.80it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  4.28it/s]\n","                   all         20         20      0.971      0.872      0.942      0.659\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      28/49      2.65G    0.01981    0.01259    0.01234         24        640: 100% 37/37 [00:06<00:00,  6.13it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  4.43it/s]\n","                   all         20         20      0.894      0.917      0.937      0.571\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      29/49      2.65G    0.02104    0.01293    0.01303         24        640: 100% 37/37 [00:07<00:00,  4.88it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  4.39it/s]\n","                   all         20         20      0.947      0.895      0.964      0.658\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      30/49      2.65G    0.01929    0.01284    0.01243         20        640: 100% 37/37 [00:06<00:00,  6.16it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  4.24it/s]\n","                   all         20         20       0.93      0.927      0.995      0.648\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      31/49      2.65G    0.01983    0.01165    0.01151         26        640: 100% 37/37 [00:07<00:00,  4.85it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  4.52it/s]\n","                   all         20         20      0.897      0.903      0.974      0.679\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      32/49      2.65G    0.02294    0.01217    0.01449         17        640: 100% 37/37 [00:06<00:00,  6.15it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  3.97it/s]\n","                   all         20         20      0.946       0.91      0.964      0.654\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      33/49      2.65G    0.01751    0.01192    0.01085         19        640: 100% 37/37 [00:07<00:00,  4.91it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  3.83it/s]\n","                   all         20         20      0.958      0.883       0.96      0.712\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      34/49      2.65G    0.02064    0.01126    0.01158         19        640: 100% 37/37 [00:06<00:00,  6.03it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  2.35it/s]\n","                   all         20         20      0.979      0.898       0.96      0.702\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      35/49      2.65G    0.01744     0.0118    0.01094         23        640: 100% 37/37 [00:07<00:00,  5.15it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  4.58it/s]\n","                   all         20         20      0.974      0.902      0.982       0.75\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      36/49      2.65G    0.02037    0.01214    0.01369         23        640: 100% 37/37 [00:06<00:00,  5.78it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  3.10it/s]\n","                   all         20         20      0.922      0.977      0.995        0.7\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      37/49      2.65G    0.01811    0.01209    0.01127         15        640: 100% 37/37 [00:06<00:00,  5.31it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  4.58it/s]\n","                   all         20         20      0.934      0.978      0.995      0.701\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      38/49      2.65G    0.01845     0.0114    0.01054         16        640: 100% 37/37 [00:06<00:00,  5.53it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  3.41it/s]\n","                   all         20         20      0.902          1      0.995      0.708\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      39/49      2.65G     0.0175    0.01254    0.01109         25        640: 100% 37/37 [00:06<00:00,  5.59it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  4.41it/s]\n","                   all         20         20        0.9          1      0.995      0.713\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      40/49      2.65G    0.01675    0.01185     0.0107         18        640: 100% 37/37 [00:06<00:00,  5.60it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  3.19it/s]\n","                   all         20         20      0.932          1      0.995      0.724\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      41/49      2.65G    0.01778    0.01128   0.009619         12        640: 100% 37/37 [00:06<00:00,  5.72it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  4.42it/s]\n","                   all         20         20      0.954          1      0.995      0.762\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      42/49      2.65G    0.01765    0.01137    0.01019         17        640: 100% 37/37 [00:07<00:00,  5.26it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  3.10it/s]\n","                   all         20         20      0.958          1      0.995      0.763\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      43/49      2.65G    0.01798    0.01079    0.01033         19        640: 100% 37/37 [00:06<00:00,  6.05it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  4.56it/s]\n","                   all         20         20      0.965          1      0.995       0.76\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      44/49      2.65G    0.01558    0.01106   0.008912         24        640: 100% 37/37 [00:07<00:00,  4.76it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  4.49it/s]\n","                   all         20         20      0.967          1      0.995       0.76\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      45/49      2.65G    0.01804    0.01101    0.01037         15        640: 100% 37/37 [00:06<00:00,  6.13it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  4.45it/s]\n","                   all         20         20      0.933          1      0.995      0.773\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      46/49      2.65G     0.0187    0.01089    0.01075         23        640: 100% 37/37 [00:07<00:00,  4.84it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  3.99it/s]\n","                   all         20         20      0.937          1      0.995      0.767\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      47/49      2.65G    0.01626    0.01057   0.009636         21        640: 100% 37/37 [00:06<00:00,  6.15it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  4.38it/s]\n","                   all         20         20       0.95          1      0.995      0.768\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      48/49      2.65G     0.0166    0.01094   0.009514         24        640: 100% 37/37 [00:07<00:00,  4.84it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  4.40it/s]\n","                   all         20         20      0.947          1      0.995       0.77\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","      49/49      2.65G    0.01689    0.01095    0.00961         20        640: 100% 37/37 [00:06<00:00,  6.05it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  4.47it/s]\n","                   all         20         20      0.946          1      0.995      0.772\n","\n","50 epochs completed in 0.108 hours.\n","Optimizer stripped from yolov5/runs/train/exp7/weights/last.pt, 14.5MB\n","Optimizer stripped from yolov5/runs/train/exp7/weights/best.pt, 14.5MB\n","\n","Validating yolov5/runs/train/exp7/weights/best.pt...\n","Fusing layers... \n","Model summary: 157 layers, 7020913 parameters, 0 gradients, 15.8 GFLOPs\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  4.02it/s]\n","                   all         20         20      0.933          1      0.995      0.762\n","                  Fist         20          8      0.926          1      0.995      0.799\n","              OpenPalm         20          5      0.911          1      0.995      0.815\n","             PeaceSign         20          3      0.907          1      0.995      0.703\n","              ThumbsUp         20          4       0.99          1      0.995      0.732\n","Results saved to \u001b[1myolov5/runs/train/exp7\u001b[0m\n"]}],"source":["!python /content/yolov5/train.py --img 640 --batch 10 --epochs 50 --data /content/yolov5/YOLOv5-Hand-Gesture-3/data.yaml  --weights yolov5s.pt --cache\n"]},{"cell_type":"markdown","source":["ðŸ¸ This line runs YOLOv5 detection on **test images** with specified parameters: weights, image size, confidence threshold, and image source directory."],"metadata":{"id":"jf2VpeDjthq9"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9058,"status":"ok","timestamp":1708889284493,"user":{"displayName":"shima azizi","userId":"03537820371144014436"},"user_tz":-210},"id":"oMtFcxmWsy5r","outputId":"b4ed46e0-e859-46d8-ac90-f1894328968a"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/content/yolov5/runs/train/exp6/weights/best.pt'], source=/content/yolov5/YOLOv5-Hand-Gesture-3/test/images, data=yolov5/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.1, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_csv=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov5/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n","YOLOv5 ðŸš€ v7.0-286-g41603da1 Python-3.10.12 torch-2.1.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n","\n","Fusing layers... \n","Model summary: 157 layers, 7020913 parameters, 0 gradients, 15.8 GFLOPs\n","WARNING âš ï¸ NMS time limit 0.550s exceeded\n","image 1/20 /content/yolov5/YOLOv5-Hand-Gesture-3/test/images/Fist_18-jpg_jpg.rf.c66bb45fe74d4688664b93d179282cc0.jpg: 640x640 2 Fists, 11.5ms\n","image 2/20 /content/yolov5/YOLOv5-Hand-Gesture-3/test/images/Fist_19-jpg_jpg.rf.d2a2802a47aa088fc233f4daa3b7ba7c.jpg: 640x640 1 Fist, 11.7ms\n","image 3/20 /content/yolov5/YOLOv5-Hand-Gesture-3/test/images/Fist_22-jpg_jpg.rf.b2a2828a1819367016d66a3d8901ee91.jpg: 640x640 1 Fist, 11.5ms\n","image 4/20 /content/yolov5/YOLOv5-Hand-Gesture-3/test/images/Fist_3-jpg_jpg.rf.dd0cfcb22a7777d4eefdb91b300e86bf.jpg: 640x640 1 Fist, 11.5ms\n","image 5/20 /content/yolov5/YOLOv5-Hand-Gesture-3/test/images/Fist_33-jpg_jpg.rf.1fc9a0dcf5e05d4d73c6931746088551.jpg: 640x640 1 Fist, 11.5ms\n","image 6/20 /content/yolov5/YOLOv5-Hand-Gesture-3/test/images/OpenPalm_15-jpg_jpg.rf.518827fcc9d8e55c1c9ebfcc9c18aba7.jpg: 640x640 1 OpenPalm, 11.5ms\n","image 7/20 /content/yolov5/YOLOv5-Hand-Gesture-3/test/images/OpenPalm_21-jpg_jpg.rf.d6fdc1555f88c6e5e21f666c39111c3f.jpg: 640x640 1 OpenPalm, 11.5ms\n","image 8/20 /content/yolov5/YOLOv5-Hand-Gesture-3/test/images/OpenPalm_37-jpg_jpg.rf.98b3484ca7d9f0bafef4953b8d8a3ce7.jpg: 640x640 1 OpenPalm, 11.5ms\n","image 9/20 /content/yolov5/YOLOv5-Hand-Gesture-3/test/images/OpenPalm_43-jpg_jpg.rf.bb76b70ab5270431bb2257ee3d27ae17.jpg: 640x640 1 OpenPalm, 11.5ms\n","image 10/20 /content/yolov5/YOLOv5-Hand-Gesture-3/test/images/OpenPalm_5-jpg_jpg.rf.1e54fc35e5ee32515cb617f6d6717fcb.jpg: 640x640 1 OpenPalm, 11.5ms\n","image 11/20 /content/yolov5/YOLOv5-Hand-Gesture-3/test/images/OpenPalm_6-jpg_jpg.rf.92c793c43e60d9645af8f0be0975fcc0.jpg: 640x640 1 OpenPalm, 11.5ms\n","image 12/20 /content/yolov5/YOLOv5-Hand-Gesture-3/test/images/OpenPalm_7-jpg_jpg.rf.61cf9186734cee7f7efadfe8982d9d8d.jpg: 640x640 1 OpenPalm, 11.5ms\n","image 13/20 /content/yolov5/YOLOv5-Hand-Gesture-3/test/images/PeaceSign_13-jpg_jpg.rf.85dce7aab4477ae870c10e81c59225bd.jpg: 640x640 1 PeaceSign, 11.5ms\n","image 14/20 /content/yolov5/YOLOv5-Hand-Gesture-3/test/images/PeaceSign_27-jpg_jpg.rf.69acf80c9144109234995613dbf71d13.jpg: 640x640 1 OpenPalm, 1 PeaceSign, 11.5ms\n","image 15/20 /content/yolov5/YOLOv5-Hand-Gesture-3/test/images/PeaceSign_5-jpg_jpg.rf.abee4e55230b278b3ce09e0bb5757fd2.jpg: 640x640 1 PeaceSign, 11.6ms\n","image 16/20 /content/yolov5/YOLOv5-Hand-Gesture-3/test/images/ThumbsUp_23-jpg_jpg.rf.046c0e6692fe10a35f08f99bd7fbdf74.jpg: 640x640 1 ThumbsUp, 11.5ms\n","image 17/20 /content/yolov5/YOLOv5-Hand-Gesture-3/test/images/ThumbsUp_24-jpg_jpg.rf.87736849049ed7301455e32c2da65426.jpg: 640x640 1 ThumbsUp, 11.6ms\n","image 18/20 /content/yolov5/YOLOv5-Hand-Gesture-3/test/images/ThumbsUp_3-jpg_jpg.rf.9aca40cf9089109fff70b4d49f3336ab.jpg: 640x640 1 ThumbsUp, 11.6ms\n","image 19/20 /content/yolov5/YOLOv5-Hand-Gesture-3/test/images/ThumbsUp_37-jpg_jpg.rf.15e3c61ee6b930121caf4d1d4f45dcde.jpg: 640x640 1 ThumbsUp, 12.4ms\n","image 20/20 /content/yolov5/YOLOv5-Hand-Gesture-3/test/images/ThumbsUp_38-jpg_jpg.rf.965fc0c49333c352a33e92a6483aa284.jpg: 640x640 1 ThumbsUp, 11.7ms\n","Speed: 0.5ms pre-process, 11.6ms inference, 44.0ms NMS per image at shape (1, 3, 640, 640)\n","Results saved to \u001b[1myolov5/runs/detect/exp2\u001b[0m\n"]}],"source":["!python /content/yolov5/detect.py --weights /content/yolov5/runs/train/exp6/weights/best.pt --img 640 --conf 0.1 --source /content/yolov5/YOLOv5-Hand-Gesture-3/test/images\n"]},{"cell_type":"markdown","source":["âœ… This code will create a grid of subplots, with each subplot showing **test images along with its bounding box predictions**, allowing you to visually inspect the model's performance."],"metadata":{"id":"n0KUt3Y7wruL"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":887,"output_embedded_package_id":"1d1CdFcBLe9ej9sWLQme37BetSF6ryAxS"},"executionInfo":{"elapsed":11773,"status":"ok","timestamp":1708889775700,"user":{"displayName":"shima azizi","userId":"03537820371144014436"},"user_tz":-210},"id":"QH2p6R0NywOa","outputId":"212d2adb-a26c-46ff-87c5-5f1a6cb32168"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["import matplotlib.pyplot as plt\n","import matplotlib.image as mpimg\n","import glob\n","\n","# Get list of image file paths\n","image_paths = glob.glob(\"/content/yolov5/runs/detect/exp/*.jpg\")\n","\n","# Define number of rows and columns for subplots\n","rows = 4\n","cols = 5\n","\n","# Create subplots with specified number of rows and columns\n","fig, axes = plt.subplots(rows, cols, figsize=(15, 15))\n","\n","# Flatten axes array to loop through it easily\n","axes = axes.flatten()\n","\n","# Loop through image paths and display each image\n","for i, image_path in enumerate(image_paths):\n","    # Read image\n","    image = mpimg.imread(image_path)\n","\n","    # Display image on corresponding subplot\n","    axes[i].imshow(image)\n","    axes[i].axis('off')  # Hide axis\n","\n","# Adjust layout to prevent overlap\n","plt.tight_layout()\n","plt.show()\n"]},{"cell_type":"code","source":[],"metadata":{"id":"wnmuHbmxxG22"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOO7aOs9cQKmJOTiTy57xnN"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}